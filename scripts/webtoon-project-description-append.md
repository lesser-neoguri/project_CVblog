## 10. 데모 구현과 시행착오

이 프로젝트에는 실제로 동작하는 **웹 데모**가 포함되어 있다. 프로젝트 상세 페이지에서 LIVE DEMO로 `/demo/webtoon-chatbot`이 iframe 임베드되며, 아래 기능들이 구현되어 있다. 구현 과정에서 겪은 시행착오와 수정 사항을 정리한다.

### 10.1 데모 구성

* **채팅 UI**: 사용자/봇 말풍선, 입력창, 전송. RAG·커스텀 설정을 반영한 시스템 프롬프트로 LLM이 답변 생성.
* **RAG 커스텀 패널**: 세계관, 성격, 말투/톤, **대화 시점**, **대화 패턴**을 입력할 수 있다. 입력 시 시스템 프롬프트에 [캐릭터 설정] 및 `### 대화 시점 ###`, `### 대화 패턴 ###` 블록으로 주입된다.
* **대화 시점·대화 패턴**: [NAVER Cloud 포스트](https://www.ncloud-forums.com/topic/382/) (HyperCLOVA X로 2시간 만에 캐릭터 챗봇 만들기)를 참고해, "현재 스토리상 어느 시점의 캐릭터인지"와 "등장인물 언급·존칭·반말/존댓말·감정·이모티콘·특정 어휘" 등 구체적 행동 규칙을 넣을 수 있게 했다.
* **API / 목업 토글**: 실제 API 호출과 키워드 기반 목업 응답을 헤더에서 전환할 수 있다. API 키가 없거나 오류 시에도 데모를 체험할 수 있도록 했다.

### 10.2 API 사용 여부가 구분되지 않던 문제

* **상황**: UI에는 "실제 API 사용 중"으로 나오는데, 응답은 전부 목업처럼 보이고 뱃지도 없어 사용자가 "API 사용이 안 되고 있다"고 느낌.
* **원인**: API 키가 없거나 서버 오류 시 **폴백으로 목업**을 쓰는데, 그때 사용자에게 **실패 사유를 알려주지 않음**. 또한 메시지별로 "이 답은 API인지 목업인지" 표시가 없어서 구분이 불가능했다.
* **수정**:
  * API 호출 실패 시(특히 503 useFallback)에도 **에러 메시지를 저장해 입력창 아래에 표시**. "API 사용 불가" 박스에 서버 메시지(예: API 키를 .env.local에 설정해 주세요)와 함께 .env.local 설정 안내를 넣었다.
  * **메시지별 출처 뱃지**: 봇 메시지에 "API" 또는 "목업" 뱃지를 붙여, 실제로 어떤 경로로 생성된 답인지 보이게 했다.
  * 헤더에 "지금: 실제 API 사용 중 / 목업 사용 중" 문구와, API 모드일 때 "(.env.local에 OPENAI_API_KEY 또는 UPSTAGE_API_KEY 필요)" 안내를 추가했다.

### 10.3 Upstage API 연동 시행착오

* **상황**: UPSTAGE_API_KEY를 넣었는데 **400 The requested model is invalid or no longer supported** 오류 발생.
* **원인 후보**:
  * 사용하던 **모델명** `solar-pro-3`가 해당 엔드포인트에서 지원되지 않거나 변경됨.
  * **Base URL** 차이: v1/solar vs v2 문서가 혼재해 있어, 엔드포인트·모델 ID 조합이 맞지 않을 수 있음.
* **수정**:
  * **Base URL**: `https://api.upstage.ai/v1/solar` 로 통일. (Upstage EduStage·Mastra 문서에서 v1/solar 사용 예시가 있음.) 환경 변수 `UPSTAGE_BASE_URL`로 덮을 수 있게 했다.
  * **모델명**: EduStage 가이드 기준으로 **`solar-mini`** (접두사 없음)를 기본값으로 사용. `UPSTAGE_CHAT_MODEL`로 변경 가능. (v2 사용 시 `upstage/solar-mini` 등 콘솔 문서의 모델 ID 사용.)
  * 데모 화면의 API 오류 안내에 "Upstage 사용 시 모델 오류(400)가 나면 UPSTAGE_CHAT_MODEL=solar-mini, UPSTAGE_BASE_URL=https://api.upstage.ai/v1/solar 를 추가해 보세요" 문구를 넣었다.

### 10.4 정리

* 데모는 **API 키 없이도 목업으로 동작**하고, API 키가 있으면 **실제 LLM + RAG**가 동작한다. API/목업 전환과 메시지별 뱃지로 어떤 경로로 응답했는지 명확히 보이도록 했다.
* Upstage를 쓸 때는 **콘솔 문서(모델 목록·Chat API)**를 확인해, 사용 중인 base URL과 모델 ID가 일치하는지 점검하는 것이 좋다.

### 10.5 스토리 전개·말투 튜닝과 로딩 UX

* **문제**
  * 초기 버전에서는 썰 응답이 번호형(`1.`, `2.`)·목록형으로 나와 **대화라기보다 요약문**처럼 보였다.
  * 한 응답을 여러 말풍선으로 나눌 때, 캐릭터가 **혼자 질문하고 혼자 답하는 자문자답**처럼 느껴졌다.
  * 인사 한마디에도 길게 우다다 말하는 경향이 있어, 짧은 캐주얼 대화가 어렵고 피로도가 높았다.
  * 청크 사이 대기 시간 동안 로딩이 꺼져 있어, 답변이 이어지는 중인지 사용자가 헷갈렸다.

* **수정 (현재 데모 동작 기준)**
  * **기본 길이 규칙**
    * 평범한 대화(인사, 짧은 질문)는 기본 **1~3문장**까지만 답하도록 프롬프트·서버 컷을 모두 조정했다.
    * 사용자가 *“자세히”, “썰 풀어줘”, “끊어서 말해줘”*처럼 요청할 때만, 길게 스토리를 전개한다.
  * **줄 단위 연재형 출력**
    * 스토리/썰 모드일 때는 모델이 줄바꿈으로 여러 줄을 생성하고, 클라이언트가 이를 **라인 단위 청크**로 잘라 한 줄씩 천천히 내보낸다.
    * 사용자가 *“한 번에 말해 / 끊지 말고”*라고 하면, 예외적으로 한 묶음으로 보낸다.
  * **말투·톤 튜닝**
    * 프롬프트에서 **이모티콘과 괄호 속 지문(예: `(기특)` 같은 속마음)**을 금지하고, 서버/클라이언트 후처리에서 실제로 제거한다.
    * 사용자의 말투가 거칠면 과장/귀여운 말투를 줄이고, 짧고 담백하게 답하도록 Adaptive 규칙을 넣었다.
    * 캐릭터 프리셋(로판, 무협, 게임 등)마다 worldView/personality/tone/storyPoint/conversationPattern을 따로 주입해, 장르·세계관에 맞는 썰을 풀도록 했다.
  * **분할 출력과 로딩 UX**
    * `splitReplyIntoChunks`를 **줄 → 문장 → 쉼표 → 길이** 순으로 분리해, 항상 “여러 큐”로 나눌 수 있게 했다.
    * 각 청크 사이를 **2~4초 랜덤 지연**으로 두고, 그동안 `isTyping`을 켜서 **점 3개 로딩 말풍선**이 계속 보이게 했다.
    * 후속 청크에는 `continuation` 플래그를 붙여, 같은 답변의 이어 말로 스타일링(상단 라벨/뱃지 생략, 위 여백 축소)했다.
    * 입력이 들어오면 진행 중인 생성(`replyGenerationRef`)을 즉시 중단해, 사용자가 중간에 끼어들어도 다음 턴부터 자연스럽게 이어갈 수 있다.

* **적용 방법 (코드 포인트)**
  * `src/lib/chat-auto-improve.ts`
    * `buildAdaptivePromptBlock`: 스토리 모드에서 줄 단위 전개, 짧은 대화/상세 요청 분기, 말투·톤 튜닝 규칙 정의.
  * `src/app/api/demo/chat/route.ts`
    * `CONVERSATION_STYLE_BASE`, `SYSTEM_PROMPT_BASE`: 번호/목록 대신 자연 문장, 한 응답 내 자문자답 금지, 이모지·괄호 지문 금지, 기본 1~3문장 규칙을 명시.
    * 응답 후처리에서 메타 블록(대화 요약 등)을 잘라내고, 길이/토큰 컷을 "짧은 대화 vs 상세 썰"에 맞게 다르게 적용.
  * `src/app/demo/webtoon-chatbot/page.tsx`
    * `sanitizeReply`: 모델이 섞어 보낸 role 라벨, 이모지, 괄호 속 무대 지문, 자동 요약 블록을 제거해 말풍선에 들어갈 순수 본문만 남긴다.
    * `splitReplyIntoChunks`: 줄 단위 → 문장 단위 → 쉼표 단위 → 강제 길이 단위 순으로 분할해, 한 답변을 여러 큐로 나눈다.
    * `shouldUseLineByLineMode`: 기본은 항상 끊어서 보여주고, *“한 번에/끊지 말고”* 요청일 때만 단일 청크로 전환한다.
    * `randomChunkDelayMs`: 각 청크 사이 딜레이를 **2~4초**로 설정.
    * `appendBotChunks`: 청크 삽입과 `isTyping` 토글을 일원화해, 대기 중에는 항상 로딩 말풍선을 보여 준다.
    * 메시지 렌더링: `continuation`이 true인 청크는 봇 이름/출처 뱃지를 숨기고 위 여백을 줄여, 같은 답변이 이어지는 것처럼 보이게 했다.

* **기대 효과**
  * 짧은 인사·질문에는 **짧고 자연스러운 한두 문장**으로 응답하고, 요청했을 때만 길게 썰을 이어간다.
  * 분할 출력이 같은 답변의 연속으로 보이기 때문에, 캐릭터가 혼자 질문·답변하는 느낌이 줄고 **연재형 대화**에 더 가깝게 느껴진다.
  * 2~4초 간격의 로딩 말풍선 덕분에, 사용자는 **“지금 이어서 쓰는 중인지”**를 항상 직관적으로 알 수 있다.
